## Preprocessing
We worked with the data in hdf5 format, with all training observations for a single chromosome in a single h5 file.
To build these files, run preprocessing/build_h5_from_bigwigs.py train and preprocessing/build_h5_from_bigwigs.py val. The --directory flag or DATA_DIR environment variable should be used to specify the directory containing the bigwigs. <dataset> takes the values train and val.

## Training

We trained models initialized with different random seeds on each chromosome
Run training/chunked_train_single_chrom.py to train on a single chromosome.


## Predictions

Given a set of saved weights (i.e. as a result of training the same model on each chromosome as outlined above), predictions were generated by computing predictions from each set of weights and averaging them.

The full pipeline can be performed by running prediction/build_prediction_ensemble.py for each chromosome to be predicted to generate npz predictions. Once predictions have been made for all chromosomes, they can be gathered into bigwigs by running prediction/save_bigwig.py
 
